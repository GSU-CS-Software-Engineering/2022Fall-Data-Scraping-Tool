import requests
import pandas as pd
from bs4 import BeautifulSoup


class WebScraper:
    def company_URL(self, name: str = None, cik: int = None,form_type: str = None,
                    head: dict = None):  # if paremeter isnt entered when called then default value is None
        self.name = name
        self.cik = cik
        self.form_type = form_type
 
        endpoint = r"https://www.sec.gov/cgi-bin/browse-edgar?"
 
        param_dict = {
                      "company": name,  # query for company names
                      'CIK': cik,  # query for numbers associated with companies
                      'type': form_type, #specify the form type wanted from the company Ex. 10-k or s-4
                      'owner': 'exclude',
                      'output': '',
                      }
 
        if name or cik: #use if user has specific company in mind
            param_dict['action'] = 'getcompany'
 
        elif form_type: #use if user wants to find all companies with a specific form type
            param_dict['action'] = 'getcurrent'
 
        response = requests.get(url=endpoint, params=param_dict, headers=head)
        self.soup = BeautifulSoup(response.content, 'html.parser')
        return self.soup
 
    def yearly_filings(self, soup, head):
        doc_table = soup.find_all('table', class_='tableFile2')
        base_url_sec = r"https://www.sec.gov"
        ten_k_soup = []
        for row in doc_table[0].find_all('tr')[0:]:
            cols = row.find_all('td')
 
            if len(cols) != 0:
                filing_date = cols[3].text.strip()
                filing_doc_href = cols[1].find('a', {'href': True, 'id': 'documentsbutton'})
 
                if filing_doc_href != None:
                    filing_doc_link = base_url_sec + filing_doc_href['href']
 
                    response = requests.get(filing_doc_link, headers=head)
                    soup = BeautifulSoup(response.content, "html.parser")
 
                    doc_table_two = soup.find('table', class_="tableFile")
                    ten_k_row = doc_table_two.find_all('tr')[1]
                    ten_k_cols = ten_k_row.find_all('td')
                    ten_k_doc_href = ten_k_cols[2].find('a', {'href': True})
 
                    if ten_k_doc_href != None:
                        ten_k_doc_link = base_url_sec + ten_k_doc_href['href']
                        ten_k_doc_link = ten_k_doc_link.replace('/ix?doc=', '')
                        response = requests.get(ten_k_doc_link, headers=head)
                        ten_k_soup.append(BeautifulSoup(response.content, 'html.parser'))
 
                    else:
                        ten_k_doc_link = 'no link'
 
                else:
                    ten_k_doc_link = 'no link'
 
                print(filing_date)
                print(ten_k_doc_link)
        return ten_k_soup
 
    def get_cik(self):  # searches the entire webpage for span element with class companyName
        company_data = soup.find("span", class_="companyName")
        # print(company_data)
        company_data_lst = [i.text for i in company_data]
        name = str(company_data_lst[0])
        cik = int(company_data_lst[-1].split(" ")[0])
        print(name, cik)
        return name, cik  # can be indexed #Ex. get_cik()[0] -> name:str or get_cik()[1] -> cik:int
 
    def get_all_companies(self): #function to get all companies under a specific form type
        print(f"Companies within a {self.form_type} form")
        table = soup.find_all("table")
 
        all_company_table = table[6] #multiple table html elements on webpage so index variable to get the main table of comapny with a specific form type
        all_companies = all_company_table.find_all("a") #returns all a html elements within the table
 
        for i in range(0,len(all_companies),4): #iterates through the list of companies in html table (every 4th item in list is a company name along with cik number) 
            name = all_companies[i].text #gets the inner text of current element
            company = name.split("(")
            name = company[0]
            cik = company[1][0:-2]
            print(name,cik)
 
 
if __name__ == "__main__":
    test = True #made this to test getting companies of 10-k form
    head = {'User-Agent': 'Georgia Southern University AdminContact@{email}'}
    w = WebScraper()
 
    if test:
        soup = w.company_URL(form_type="10-k", head=head)  # name and cik are optional parameters but it needs 1 of them
        w.get_all_companies()
 
    else:
        name = input("Enter the company name: ")
        cik = input("Enter the company 10 digit CIK number: ")
        form_type = input("Enter the specific form type for the company: ")
        print("Enter your school email:")
        email = input("Enter your school email: ")
 
        soup = w.company_URL(name=name, cik=cik, form_type=form_type, head=head)  # name and cik are optional parameters but it needs 1 of them
        if name or cik: #checks if user has a specific company in mind if so queries db using headers to get that specific company
            company = w.get_cik()
            print(company)
 
            for x in w.yearly_filings(soup, head):
                print(x.text)
 
        elif form_type: #checks if user doesnt have a specific company in mind and just wants to find all companies with a specific form type Ex. s-4,10-k,...
            pass
 
